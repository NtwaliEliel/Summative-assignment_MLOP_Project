{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPxU6AQxv4TUSbTVBHc/tqL",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/NtwaliEliel/Summative-assignment_MLOP_Project/blob/main/Summative_assignment_MLOP.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uOYV85Aa5phl",
        "outputId": "5b9e8699-bc8b-4ab9-976d-b95fb0f96c63"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Base path: /content/drive/MyDrive/mlops-project\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')  # follow the link and paste auth code\n",
        "BASE = \"/content/drive/MyDrive/mlops-project\"\n",
        "print(\"Base path:\", BASE)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "BASE = \"/content/drive/MyDrive/mlops-project\"\n",
        "folders = [\"notebook\",\"api\",\"model\",\"retrain/new_data\",\"ui/assets\",\"docker\"]\n",
        "for f in folders:\n",
        "    os.makedirs(os.path.join(BASE,f), exist_ok=True)\n",
        "print(\"Folders created under\", BASE)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3SwrxjcCDJ8R",
        "outputId": "f87bf71f-3224-4a88-982e-2b6da405b183"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Folders created under /content/drive/MyDrive/mlops-project\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# run in a code cell (keep the leading !)\n",
        "!pip install -q fastapi uvicorn[standard] python-multipart joblib scikit-learn pyngrok\n"
      ],
      "metadata": {
        "id": "AYkU-MHPDeMf"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train, evaluate, and save model & scaler to Drive\n",
        "import joblib, os\n",
        "import pandas as pd, numpy as np\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report, confusion_matrix\n",
        "\n",
        "BASE = \"/content/drive/MyDrive/mlops-project\"\n",
        "\n",
        "# 1. Load data\n",
        "iris = load_iris(as_frame=True)\n",
        "df = iris.frame.copy()\n",
        "df['target'] = iris.target\n",
        "\n",
        "# 2. Train/test split\n",
        "X = df.drop(columns=['target'])\n",
        "y = df['target']\n",
        "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2, random_state=42, stratify=y)\n",
        "\n",
        "# 3. Scale\n",
        "scaler = StandardScaler().fit(X_train)\n",
        "X_train_s = scaler.transform(X_train)\n",
        "X_test_s = scaler.transform(X_test)\n",
        "\n",
        "# 4. Grid search optimize logistic regression (simple but valid)\n",
        "params = {'C':[0.01,0.1,1,10,100]}\n",
        "grid = GridSearchCV(LogisticRegression(max_iter=1500), params, cv=5)\n",
        "grid.fit(X_train_s, y_train)\n",
        "best = grid.best_estimator_\n",
        "\n",
        "# 5. Evaluate (required 4 metrics)\n",
        "y_pred = best.predict(X_test_s)\n",
        "acc = accuracy_score(y_test,y_pred)\n",
        "prec = precision_score(y_test,y_pred, average='macro')\n",
        "rec = recall_score(y_test,y_pred, average='macro')\n",
        "f1 = f1_score(y_test,y_pred, average='macro')\n",
        "\n",
        "print(\"BEST PARAMS:\", grid.best_params_)\n",
        "print(\"Accuracy:\", acc)\n",
        "print(\"Precision (macro):\", prec)\n",
        "print(\"Recall (macro):\", rec)\n",
        "print(\"F1 (macro):\", f1)\n",
        "print(\"\\nCLASSIFICATION REPORT:\\n\", classification_report(y_test,y_pred, target_names=iris.target_names))\n",
        "print(\"CONFUSION MATRIX:\\n\", confusion_matrix(y_test,y_pred))\n",
        "\n",
        "# 6. Save model and scaler to Drive\n",
        "os.makedirs(os.path.join(BASE,\"model\"), exist_ok=True)\n",
        "joblib.dump(best, os.path.join(BASE,\"model\",\"iris_model.pkl\"))\n",
        "joblib.dump(scaler, os.path.join(BASE,\"model\",\"scaler.pkl\"))\n",
        "print(\"Saved model & scaler to\", os.path.join(BASE,\"model\"))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ozJCUuBHDo4h",
        "outputId": "563ef01f-60cf-4d37-9565-700114869116"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BEST PARAMS: {'C': 10}\n",
            "Accuracy: 1.0\n",
            "Precision (macro): 1.0\n",
            "Recall (macro): 1.0\n",
            "F1 (macro): 1.0\n",
            "\n",
            "CLASSIFICATION REPORT:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "      setosa       1.00      1.00      1.00        10\n",
            "  versicolor       1.00      1.00      1.00        10\n",
            "   virginica       1.00      1.00      1.00        10\n",
            "\n",
            "    accuracy                           1.00        30\n",
            "   macro avg       1.00      1.00      1.00        30\n",
            "weighted avg       1.00      1.00      1.00        30\n",
            "\n",
            "CONFUSION MATRIX:\n",
            " [[10  0  0]\n",
            " [ 0 10  0]\n",
            " [ 0  0 10]]\n",
            "Saved model & scaler to /content/drive/MyDrive/mlops-project/model\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt, seaborn as sns, os\n",
        "BASE = \"/content/drive/MyDrive/mlops-project\"\n",
        "os.makedirs(os.path.join(BASE,\"ui\",\"assets\"), exist_ok=True)\n",
        "\n",
        "# class distribution\n",
        "sns.countplot(x=df['target'])\n",
        "plt.title(\"Class distribution\")\n",
        "plt.savefig(os.path.join(BASE,\"ui\",\"assets\",\"class_distribution.png\"))\n",
        "plt.clf()\n",
        "\n",
        "# correlation heatmap\n",
        "sns.heatmap(df.drop(columns='target').corr(), annot=True)\n",
        "plt.title(\"Feature correlation\")\n",
        "plt.savefig(os.path.join(BASE,\"ui\",\"assets\",\"correlation.png\"))\n",
        "plt.clf()\n",
        "\n",
        "# confusion matrix (recompute)\n",
        "from sklearn.metrics import confusion_matrix\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "sns.heatmap(cm, annot=True, fmt=\"d\")\n",
        "plt.title(\"Confusion Matrix\")\n",
        "plt.savefig(os.path.join(BASE,\"ui\",\"assets\",\"confusion_matrix.png\"))\n",
        "plt.clf()\n",
        "\n",
        "print(\"Saved plots to\", os.path.join(BASE,\"ui\",\"assets\"))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "NLm0ZIm8ED6F",
        "outputId": "615c7dd7-0388-4e9c-b65f-73252893a712"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved plots to /content/drive/MyDrive/mlops-project/ui/assets\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 0 Axes>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "BASE=\"/content/drive/MyDrive/mlops-project\"\n",
        "cat > $BASE/api/main.py <<'PY'\n",
        "from fastapi import FastAPI\n",
        "from pydantic import BaseModel\n",
        "import joblib, numpy as np\n",
        "MODEL_PATH = \"/content/drive/MyDrive/mlops-project/model/iris_model.pkl\"\n",
        "SCALER_PATH = \"/content/drive/MyDrive/mlops-project/model/scaler.pkl\"\n",
        "app = FastAPI()\n",
        "\n",
        "class PredictIn(BaseModel):\n",
        "    sepal_length: float\n",
        "    sepal_width: float\n",
        "    petal_length: float\n",
        "    petal_width: float\n",
        "\n",
        "def load_model():\n",
        "    model = joblib.load(MODEL_PATH)\n",
        "    scaler = joblib.load(SCALER_PATH)\n",
        "    return model, scaler\n",
        "\n",
        "@app.post(\"/predict\")\n",
        "async def predict(payload: PredictIn):\n",
        "    model, scaler = load_model()\n",
        "    X = np.array([[payload.sepal_length, payload.sepal_width, payload.petal_length, payload.petal_width]])\n",
        "    Xs = scaler.transform(X)\n",
        "    pred = int(model.predict(Xs)[0])\n",
        "    proba = float(model.predict_proba(Xs).max())\n",
        "    return {\"prediction\": pred, \"probability\": proba}\n",
        "PY\n",
        "echo \"FastAPI app saved to Drive at /api/main.py\"\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K8WuK7EVLlJ_",
        "outputId": "3b22806d-a6b3-43bc-f4d0-d8528c590b5f"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FastAPI app saved to Drive at /api/main.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# CELL 7: Start uvicorn and ngrok tunnel (optional)\n",
        "from pyngrok import ngrok, conf\n",
        "import os, time\n",
        "\n",
        "BASE = \"/content/drive/MyDrive/mlops-project\"\n",
        "API_DIR = os.path.join(BASE, \"api\")\n",
        "os.chdir(API_DIR)\n",
        "\n",
        "# If you have a token\n",
        "NGROK_AUTH_TOKEN = \"35nRKcgfPFLp8D5p2Q2Luf5cGiq_TArmpswMFHfijf73nL1n\"  # paste your token here if you have one\n",
        "if NGROK_AUTH_TOKEN:\n",
        "    conf.get_default().auth_token = NGROK_AUTH_TOKEN\n",
        "\n",
        "# Kill any existing ngrok processes to avoid hitting the limit on free accounts\n",
        "ngrok.kill()\n",
        "\n",
        "# Start uvicorn in background\n",
        "get_ipython().system_raw(\"uvicorn main:app --host 0.0.0.0 --port 8000 &\")\n",
        "\n",
        "time.sleep(2)  # wait for server to start\n",
        "\n",
        "# Start ngrok tunnel\n",
        "public_url = ngrok.connect(8000)\n",
        "print(\"Public URL:\", public_url)\n",
        "print(\"Swagger docs:\", public_url.public_url + \"/docs\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DqeWejg5TE2w",
        "outputId": "53001b4d-55f7-4577-bb96-4e293d175809"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Public URL: NgrokTunnel: \"https://braelynn-grabbable-conclusively.ngrok-free.dev\" -> \"http://localhost:8000\"\n",
            "Swagger docs: https://braelynn-grabbable-conclusively.ngrok-free.dev/docs\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "BASE=\"/content/drive/MyDrive/mlops-project\"\n",
        "cat > $BASE/ui/index.html <<'HTML'\n",
        "<!doctype html>\n",
        "<html>\n",
        "<head><meta charset=\"utf-8\"><title>Iris Predictor</title></head>\n",
        "<body>\n",
        "  <h1>Iris Predictor</h1>\n",
        "  <div>\n",
        "    <label>sepal_length <input id=\"sl\" /></label><br/>\n",
        "    <label>sepal_width <input id=\"sw\" /></label><br/>\n",
        "    <label>petal_length <input id=\"pl\" /></label><br/>\n",
        "    <label>petal_width <input id=\"pw\" /></label><br/>\n",
        "    <button id=\"predictBtn\">Predict</button>\n",
        "    <pre id=\"result\"></pre>\n",
        "  </div>\n",
        "\n",
        "  <h2>Retrain (upload CSV to Drive/retrain/new_data)</h2>\n",
        "  <p>To retrain: upload a CSV to Drive â†’ run retrain cell in Colab. CSV must contain feature columns and a <strong>target</strong> column.</p>\n",
        "\n",
        "<script>\n",
        "const API_URL = \"https://braelynn-grabbable-conclusively.ngrok-free.dev\"; // If using ngrok, paste the public URL here, e.g. \"https://abcd-1234.ngrok.io\"\n",
        "document.getElementById('predictBtn').onclick = async () => {\n",
        "  const body = {\n",
        "    sepal_length: parseFloat(document.getElementById('sl').value),\n",
        "    sepal_width: parseFloat(document.getElementById('sw').value),\n",
        "    petal_length: parseFloat(document.getElementById('pl').value),\n",
        "    petal_width: parseFloat(document.getElementById('pw').value)\n",
        "  };\n",
        "  if (!API_URL) { alert(\"Set API_URL inside the file to the deployed API or ngrok URL\"); return; }\n",
        "  const res = await fetch(API_URL + \"/predict\", {\n",
        "    method:\"POST\", headers: {'Content-Type':'application/json'}, body: JSON.stringify(body)\n",
        "  });\n",
        "  const j = await res.json();\n",
        "  document.getElementById('result').innerText = JSON.stringify(j, null, 2);\n",
        "};\n",
        "</script>\n",
        "</body>\n",
        "</html>\n",
        "HTML\n",
        "echo \"UI saved to Drive at ui/index.html\"\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z_XPOdoQLne6",
        "outputId": "15aa01ea-7163-4ad5-8b28-b82b47bb1d2c"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "UI saved to Drive at ui/index.html\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# CELL 9: show an example CSV you can create locally and upload to Drive/retrain/new_data\n",
        "example_csv = \"\"\"sepal_length,sepal_width,petal_length,petal_width,target\n",
        "5.1,3.5,1.4,0.2,0\n",
        "6.0,2.2,4.0,1.0,1\n",
        "6.5,3.0,5.2,2.0,2\n",
        "\"\"\"\n",
        "print(\"Copy this text to a file named extra_iris.csv and upload it to Drive -> mlops-project/retrain/new_data\")\n",
        "print(example_csv)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7tZ49T86Te3T",
        "outputId": "a99add18-8ec8-45bb-f1bb-5be24512daf9"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Copy this text to a file named extra_iris.csv and upload it to Drive -> mlops-project/retrain/new_data\n",
            "sepal_length,sepal_width,petal_length,petal_width,target\n",
            "5.1,3.5,1.4,0.2,0\n",
            "6.0,2.2,4.0,1.0,1\n",
            "6.5,3.0,5.2,2.0,2\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Retrain model from files in Drive/retrain/new_data and overwrite model & scaler\n",
        "import glob, os, joblib, pandas as pd\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "BASE = \"/content/drive/MyDrive/mlops-project\"\n",
        "UPLOAD_DIR = os.path.join(BASE,\"retrain\",\"new_data\")\n",
        "\n",
        "print(\"Looking for CSVs in\", UPLOAD_DIR)\n",
        "files = glob.glob(os.path.join(UPLOAD_DIR, \"*.csv\"))\n",
        "print(\"Found files:\", files)\n",
        "if not files:\n",
        "    print(\"No files found. Upload a CSV to Drive/retrain/new_data and re-run this cell.\")\n",
        "else:\n",
        "    # load base iris data\n",
        "    from sklearn.datasets import load_iris\n",
        "    iris = load_iris(as_frame=True)\n",
        "    base_df = iris.frame.copy()\n",
        "    base_df['target'] = iris.target\n",
        "\n",
        "    new_dfs = []\n",
        "    for f in files:\n",
        "        df_new = pd.read_csv(f)\n",
        "        if 'target' not in df_new.columns:\n",
        "            raise ValueError(f\"CSV {f} must include a 'target' column.\")\n",
        "        new_dfs.append(df_new)\n",
        "    new_data = pd.concat(new_dfs, ignore_index=True)\n",
        "    combined = pd.concat([base_df, new_data], ignore_index=True)\n",
        "\n",
        "    X = combined.drop(columns=['target'])\n",
        "    y = combined['target']\n",
        "    scaler = StandardScaler().fit(X)\n",
        "    X_s = scaler.transform(X)\n",
        "    model = LogisticRegression(max_iter=1500)\n",
        "    model.fit(X_s,y)\n",
        "\n",
        "    # save\n",
        "    os.makedirs(os.path.join(BASE,\"model\"), exist_ok=True)\n",
        "    joblib.dump(model, os.path.join(BASE,\"model\",\"iris_model.pkl\"))\n",
        "    joblib.dump(scaler, os.path.join(BASE,\"model\",\"scaler.pkl\"))\n",
        "    print(\"Retrained model saved to\", os.path.join(BASE,\"model\"))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KSIJuRfCE8iB",
        "outputId": "7db4fac6-bcdd-42b5-ba19-eb125434bab3"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking for CSVs in /content/drive/MyDrive/mlops-project/retrain/new_data\n",
            "Found files: []\n",
            "No files found. Upload a CSV to Drive/retrain/new_data and re-run this cell.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate current model from Drive (after retrain)\n",
        "import joblib, os\n",
        "import numpy as np\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report, confusion_matrix\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "BASE = \"/content/drive/MyDrive/mlops-project\"\n",
        "model = joblib.load(os.path.join(BASE,\"model\",\"iris_model.pkl\"))\n",
        "scaler = joblib.load(os.path.join(BASE,\"model\",\"scaler.pkl\"))\n",
        "\n",
        "iris = load_iris(as_frame=True)\n",
        "df = iris.frame.copy(); df['target'] = iris.target\n",
        "X = df.drop(columns=['target']); y = df['target']\n",
        "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2, random_state=42, stratify=y)\n",
        "X_test_s = scaler.transform(X_test)\n",
        "\n",
        "y_pred = model.predict(X_test_s)\n",
        "print(\"Accuracy:\", accuracy_score(y_test,y_pred))\n",
        "print(\"Precision (macro):\", precision_score(y_test,y_pred, average='macro'))\n",
        "print(\"Recall (macro):\", recall_score(y_test,y_pred, average='macro'))\n",
        "print(\"F1 (macro):\", f1_score(y_test,y_pred, average='macro'))\n",
        "print(\"\\nClassification report:\\n\", classification_report(y_test,y_pred, target_names=iris.target_names))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "knsJxNk-HW7u",
        "outputId": "95ec372e-39d6-4dc6-8410-88245e7095c4"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 1.0\n",
            "Precision (macro): 1.0\n",
            "Recall (macro): 1.0\n",
            "F1 (macro): 1.0\n",
            "\n",
            "Classification report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "      setosa       1.00      1.00      1.00        10\n",
            "  versicolor       1.00      1.00      1.00        10\n",
            "   virginica       1.00      1.00      1.00        10\n",
            "\n",
            "    accuracy                           1.00        30\n",
            "   macro avg       1.00      1.00      1.00        30\n",
            "weighted avg       1.00      1.00      1.00        30\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Quick local check of predicted label mapping\n",
        "import joblib, numpy as np, os\n",
        "BASE = \"/content/drive/MyDrive/mlops-project\"\n",
        "model = joblib.load(os.path.join(BASE,\"model\",\"iris_model.pkl\"))\n",
        "scaler = joblib.load(os.path.join(BASE,\"model\",\"scaler.pkl\"))\n",
        "\n",
        "# Example point (setosa): 5.1,3.5,1.4,0.2\n",
        "X = np.array([[5.1,3.5,1.4,0.2]])\n",
        "Xs = scaler.transform(X)\n",
        "pred = int(model.predict(Xs)[0])\n",
        "proba = float(model.predict_proba(Xs).max())\n",
        "print(\"Prediction:\", pred, \"Probability:\", proba)\n",
        "print(\"Label mapping: 0=setosa, 1=versicolor, 2=virginica\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AsWOTtf5Hcis",
        "outputId": "f08d779b-c793-47f4-fa51-65762d254772"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prediction: 0 Probability: 0.9974832121991416\n",
            "Label mapping: 0=setosa, 1=versicolor, 2=virginica\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# CELL 13: zip the project for submission (creates a downloadable zip in Drive)\n",
        "!zip -r /content/drive/MyDrive/mlops-project_submission.zip /content/drive/MyDrive/mlops-project\n",
        "print(\"Created ZIP at /content/drive/MyDrive/mlops-project_submission.zip\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a3tWBBzeHoTE",
        "outputId": "c24e210a-bd91-440e-88e4-d2e3ff07ca78"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "updating: content/drive/MyDrive/mlops-project/ (stored 0%)\n",
            "updating: content/drive/MyDrive/mlops-project/Summative assignment - MLOP.ipynb (deflated 74%)\n",
            "updating: content/drive/MyDrive/mlops-project/notebook/ (stored 0%)\n",
            "updating: content/drive/MyDrive/mlops-project/api/ (stored 0%)\n",
            "updating: content/drive/MyDrive/mlops-project/api/main.py (deflated 54%)\n",
            "updating: content/drive/MyDrive/mlops-project/api/.ipynb_checkpoints/ (stored 0%)\n",
            "updating: content/drive/MyDrive/mlops-project/model/ (stored 0%)\n",
            "updating: content/drive/MyDrive/mlops-project/model/iris_model.pkl (deflated 31%)\n",
            "updating: content/drive/MyDrive/mlops-project/model/scaler.pkl (deflated 40%)\n",
            "updating: content/drive/MyDrive/mlops-project/retrain/ (stored 0%)\n",
            "updating: content/drive/MyDrive/mlops-project/retrain/new_data/ (stored 0%)\n",
            "updating: content/drive/MyDrive/mlops-project/ui/ (stored 0%)\n",
            "updating: content/drive/MyDrive/mlops-project/ui/assets/ (stored 0%)\n",
            "updating: content/drive/MyDrive/mlops-project/ui/assets/class_distribution.png (deflated 23%)\n",
            "updating: content/drive/MyDrive/mlops-project/ui/assets/correlation.png (deflated 12%)\n",
            "updating: content/drive/MyDrive/mlops-project/ui/assets/confusion_matrix.png (deflated 19%)\n",
            "updating: content/drive/MyDrive/mlops-project/ui/index.html (deflated 53%)\n",
            "updating: content/drive/MyDrive/mlops-project/ui/.ipynb_checkpoints/ (stored 0%)\n",
            "updating: content/drive/MyDrive/mlops-project/docker/ (stored 0%)\n",
            "updating: content/drive/MyDrive/mlops-project/README.md (stored 0%)\n",
            "updating: content/drive/MyDrive/mlops-project/.ipynb_checkpoints/ (stored 0%)\n",
            "  adding: content/drive/MyDrive/mlops-project/api/__pycache__/ (stored 0%)\n",
            "  adding: content/drive/MyDrive/mlops-project/api/__pycache__/main.cpython-312.pyc (deflated 42%)\n",
            "Created ZIP at /content/drive/MyDrive/mlops-project_submission.zip\n"
          ]
        }
      ]
    }
  ]
}